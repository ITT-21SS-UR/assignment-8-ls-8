{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short example for using Support Vector Machines (and machine-learning classifiers in general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (12.0, 8.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(x,y,category=None):\n",
    "    plt_width = (len(x)+2)*max(x)+1\n",
    "    plt_height = max(y)+1\n",
    "    plt.figure(figsize=(plt_width, plt_height))\n",
    "    plt.xlim((0, plt_width))\n",
    "    plt.ylim((0,plt_height))\n",
    "    ax = plt.gca()\n",
    "    for i in range(len(x)):\n",
    "        if category:\n",
    "            rect = matplotlib.patches.Rectangle((i*6 + 1,0),x1[i],y1[i],linewidth=1, facecolor='r' if category[i] == 0 else 'g')\n",
    "        else:\n",
    "            rect = matplotlib.patches.Rectangle((i*6 + 1,0),x1[i],y1[i],linewidth=1, facecolor='b')\n",
    "        ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "# e.g. dimensions of boxes\n",
    "x1 = [1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 5.0] # width of the box\n",
    "y1 = [3.0, 2.0, 4.0, 1.0, 5.0, 2.0, 4.0, 3.0] # height of the box\n",
    "\n",
    "draw_boxes(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifications\n",
    "c1 = [ 0 ,  1 ,  0 ,  1 ,  0 ,  1 ,  0 ,  1 ] # possible categorization #1 (high vs. short box)\n",
    "c2 = [ 0 ,  1 ,  1 ,  0 ,  0 ,  1 ,  1 ,  0 ] # possible categorization #2 (user-selected 'nice' boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c1 = [ 0 ,  1 ,  0 ,  1 ,  0 ,  1 ,  0 ,  1 ] # possible categorization #1 (high vs. short box)\n",
    "\n",
    "draw_boxes(x1,y1,c1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a slightly less obvious classification\n",
    "c2 = [ 0 ,  1 ,  1 ,  0 ,  0 ,  1 ,  1 ,  0 ] # possible categorization #2 (user-selected 'nice' boxes)\n",
    "\n",
    "draw_boxes(x1,y1,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sample we want to classify\n",
    "xu = 3.5\n",
    "yu = 3.5\n",
    "\n",
    "draw_boxes([xu],[yu])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(x1,y1,c='y')\n",
    "scatter([xu],[yu], c='b', marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorization 1 (aspect ratio)\n",
    "\n",
    "# need to construct helper lists as pyplot.scatter does not allow for marker lists\n",
    "xa = [i[0] for i in zip(x1,c1) if i[1] == 0]\n",
    "ya = [i[0] for i in zip(y1,c1) if i[1] == 0]\n",
    "\n",
    "xb = [i[0] for i in zip(x1,c1) if i[1] == 1]\n",
    "yb = [i[0] for i in zip(y1,c1) if i[1] == 1]\n",
    "\n",
    "scatter(xa,ya,marker='+', c='r')\n",
    "scatter(xb,yb,marker='o', c='g')\n",
    "scatter([xu],[yu], marker='x', c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = [i[0] for i in zip(x1,c2) if i[1] == 0]\n",
    "yc = [i[0] for i in zip(y1,c2) if i[1] == 0]\n",
    "\n",
    "xd = [i[0] for i in zip(x1,c2) if i[1] == 1]\n",
    "yd = [i[0] for i in zip(y1,c2) if i[1] == 1]\n",
    "\n",
    "scatter(xc,yc,marker='+', c='r')\n",
    "scatter(xd,yd,marker='o', c='g')\n",
    "scatter([xu],[yu], marker='x', c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** transform data in such a way that the characteristic components are available as numerical or categorical values.\n",
    "\n",
    "**Example:** apply FFT to a waveform to extract frequency components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[usually consists of two steps](http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling):\n",
    "\n",
    "* **mean removal** ('center' all values around mean)\n",
    "* **normalization** (map all values to a certain range)\n",
    "\n",
    "([When to standardize data](http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(zip(x1,y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_samples = scale(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xy = list(zip(*scaled_samples))\n",
    "scatter(*xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fit(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_samples = s.transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = list(zip(*scaled_samples))\n",
    "scatter(*xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (using Support Vector Machines (SVMs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vectors for SVMs must have the same length!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(samples, c1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_class = classifier.predict([[xu,yu]])\n",
    "print(u_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa = [i[0] for i in zip(x1,c1) if i[1] == 0]\n",
    "ya = [i[0] for i in zip(y1,c1) if i[1] == 0]\n",
    "\n",
    "xb = [i[0] for i in zip(x1,c1) if i[1] == 1]\n",
    "yb = [i[0] for i in zip(y1,c1) if i[1] == 1]\n",
    "\n",
    "scatter(xa,ya,marker='+', c='r')\n",
    "scatter(xb,yb,marker='o', c='g')\n",
    "if u_class[0] == 0:\n",
    "    scatter([xu],[yu], marker='+', c='b')\n",
    "else:\n",
    "    scatter([xu],[yu], marker='o', c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(samples, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_class = classifier.predict([[xu,yu]])\n",
    "print(u_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xc = [i[0] for i in zip(x1,c2) if i[1] == 0]\n",
    "yc = [i[0] for i in zip(y1,c2) if i[1] == 0]\n",
    "\n",
    "xd = [i[0] for i in zip(x1,c2) if i[1] == 1]\n",
    "yd = [i[0] for i in zip(y1,c2) if i[1] == 1]\n",
    "\n",
    "scatter(xc,yc,marker='+', c='r')\n",
    "scatter(xd,yd,marker='o', c='g')\n",
    "if u_class[0] == 0:\n",
    "    scatter([xu],[yu], marker='+', c='b')\n",
    "else:\n",
    "    scatter([xu],[yu], marker='o', c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing the decision surface of a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "plot_colors = \"ryb\"\n",
    "plot_step=0.02\n",
    "xx, yy = np.meshgrid(np.arange(min(x1), max(x1), plot_step),\n",
    "                         np.arange(min(y1), max(y1), plot_step))\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "zz = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "zz = zz.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, zz, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "scatter(xc,yc,marker='+', c='k')\n",
    "scatter(xd,yd,marker='o', c='k')\n",
    "scatter([xu],[yu], marker='x', c='k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same approach with a multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(samples, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(samples, c1)\n",
    "u_class = clf.predict([[xu,yu]])\n",
    "print(u_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(samples, c2)\n",
    "u_class = clf.predict([[xu,yu]])\n",
    "print(u_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_classes = 3\n",
    "#plot_colors = \"ryb\"\n",
    "plot_step=0.02\n",
    "xx, yy = np.meshgrid(np.arange(min(x1), max(x1), plot_step),\n",
    "                         np.arange(min(y1), max(y1), plot_step))\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "zz = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "zz = zz.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, zz, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "scatter(xc,yc,marker='+', c='k')\n",
    "scatter(xd,yd,marker='o', c='k')\n",
    "scatter([xu],[yu], marker='x', c='k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same approach with a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(samples, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_class = clf.predict([[xu,yu]])\n",
    "print(u_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tree.export_text(clf))\n",
    "tree.plot_tree(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(samples, c2)\n",
    "u_class = clf.predict([[xu,yu]])\n",
    "print(u_class)\n",
    "print(tree.export_text(clf))\n",
    "tree.plot_tree(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(\"wrong\" result, i.e. different from our intuition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_classes = 3\n",
    "#plot_colors = \"ryb\"\n",
    "plot_step=0.02\n",
    "xx, yy = np.meshgrid(np.arange(min(x1), max(x1), plot_step),\n",
    "                         np.arange(min(y1), max(y1), plot_step))\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "zz = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "zz = zz.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, zz, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "scatter(xc,yc,marker='+', c='k')\n",
    "scatter(xd,yd,marker='o', c='k')\n",
    "scatter([xu],[yu], marker='x', c='k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: for analog/continuous data (e.g., most sensor data), SVM is a reliable, well-understood choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlook: scikit-learn offers many more features, tools, and classifiers, e.g., [Pipelines](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
